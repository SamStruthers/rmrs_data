---
title: "Q and Precip downloader"
author: "Sam Struthers"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
source("scripts/00_setup.R")
```

# DWR Grabber

## DWR CLP/ BIGT sites

```{r SiteGrabber}


#Station and diversion metadata

CLP_diversions <- get_structures(water_district = 3)%>%
  filter(!is.na(longdecdeg) &!is.na(longdecdeg))%>%
  filter(structure_type %in% c("STREAM GAGE","RESERVOIR SYSTEM", "MEASURING POINT", "RESERVOIR", "DITCH"))%>%
  st_as_sf(coords = c("longdecdeg", "latdecdeg"), crs = 4326)

CLP_stations <- get_sw_stations(water_district = 3)
extra_stations <- cdssr::get_sw_stations(water_district = 48)
extra_stations_2 <- cdssr::get_sw_stations(water_district = 76)

#combine all stations
all_stations <- rbind(CLP_stations, extra_stations, extra_stations_2)%>%
  filter(!is.na(longitude)&!is.na(latitude))%>%
  mutate(end_year = year(end_date),
    status = case_when(end_year >= 2022 ~ "Active",
                            end_year < 2022 ~ "Historical"), 
    start_date = as.Date(start_date), 
    end_date = as.Date(end_date))%>%
  st_as_sf(coords = c("longitude", "latitude"), crs = 4326)

#pick out active sites
active_usgs <- filter(all_stations,status == "Active"& data_source == "USGS")
active_dwr <- filter(all_stations,status == "Active"& data_source == "DWR")
#write_csv_arrow(active_dwr, "data/Q_modeling/active_dwr_sites.csv")


```

### Stations Map

```{r}

#Watershed areas

clp <- get_huc(id = "10190007", type = "huc08")


#Map!
DWR_map <- mapview::mapview(active_usgs, col.regions = "blue", layer.name = "Active USGS Stations")+
  mapview::mapview(active_dwr, col.regions = "orange", layer.name = "Active DWR Stations")+
  mapview::mapview(filter(all_stations,status != "Active"), col.regions = "purple", layer.name = "Historical Stations")+
  mapview::mapview(CLP_diversions, col.regions = "red", cex = 2, layer.name = "All Structures")+
  mapview::mapview(clp, col.regions = "green", layer.name = "CLP watershed")
  # mapview::mapview(bigt, col.regions = "cyan", layer.name = "Big Thompson Watershed")


DWR_map

```

## Station Q
### DWR
```{r}



#Grab active site numbers
station_nums<- active_dwr%>%
  st_drop_geometry()%>%
  select(station_num)%>%
  pull()

#Grab discharge data from DWR from active sites


active_dwr_Q <- map_dfr(station_nums, ~get_sw_ts(station_number = .x, start_date = "2020-01-01"))

#check units and type
unique(active_dwr_Q$meas_unit)
unique(active_dwr_Q$meas_type)
unique(active_dwr_Q$abbrev)
unique(active_dwr_Q$flag_a)

cleaned_Q_dwr <- active_dwr_Q%>%
  filter(value >= 0)
```
## USGS
```{r}



#Grab active site numbers
station_nums<- active_usgs%>%
  st_drop_geometry()%>%
  select(station_num)%>%
  pull()

#Grab discharge data from DWR from active sites


active_usgs_Q <- map_dfr(station_nums, ~get_sw_ts(station_number = .x, start_date = "2020-01-01"))

#check units and type
unique(active_usgs_Q$meas_unit)
unique(active_usgs_Q$meas_type)
unique(active_usgs_Q$abbrev)
unique(active_usgs_Q$flag_a)

cleaned_Q_usgs <- active_usgs_Q%>%
  filter(value >= 0)
```

# Plotting DWR Data

```{r}
cleaned_Q <- bind_rows(cleaned_Q_usgs, cleaned_Q_dwr)


DWR_station_plot <- cleaned_Q %>%
  ggplot(aes(x= datetime, y = value, color = flag_a, group = station_num ))+
  geom_line()+
  theme_bw()+
  ylab("Daily Q cfs")+
  xlab("Date")+
  #scale_y_log10()+
  facet_wrap(~abbrev)
plot(DWR_station_plot)

```

Exporting active DWR sites

```{r}

write_feather(cleaned_Q, sink = "data/dwr_usgs_Q_2020_2023")

```


# Larimer CO grabber

## Sites with Q

This section will create urls for used to pull in all sites in the  Cache La Poudre (CLP) and Big Thompson (BIGT) watersheds. 

## Functions

```{r url functions}
#Create urls for metadata pulls
create_meta_url <- function(site_num){

  start_url <- "https://larimerco-ns5.trilynx-novastar.systems/novastar/data/api/v1/stationSummaries?forOperatorStationDashboard=true&stationNumId="
  final_url <- tibble( site_number = site_num, 
                       site_url = paste0(start_url, site_num))
  return(final_url)
}

#Create urls for Q or other sensor pulling
create_data_url <- function(site_num){
  end_dt <- "2023-12-00T13:30:00-07:00"
  start_url <- "https://larimerco-ns5.trilynx-novastar.systems/novastar/data/api/v1/stationSummaries?forOperatorStationDashboard=true&stationNumId="
  mid_url <- "&periodStart=2020-01-01T00:00:00-07:00&periodEnd="
  
  final_url <- tibble( site_number = site_num, 
                      site_url = paste0(start_url, site_num, mid_url, end_dt))
  return(final_url)
}

```

## Create urls
```{r}
#Station numbers
clp_Q_site_nums <- tibble(station_ids = c("11531", "11530", "11525", 
                    "11514", "11004", "11515",
                    "11518", "11517", "11516",
                    "6770", "11083", "11082",
                    "11009","7130","10408", "11021"))

#Meta URLs
clp_meta_url <- map_dfr(clp_Q_site_nums, create_meta_url)%>%
  as.data.frame()


#Data URLs
clp_data_url <- map_dfr(clp_Q_site_nums, create_data_url)%>%
  as.data.frame()

```

# Getting metadata

```{r metadata}


get_station_meta <- function(site_meta_url, site_number){
  
  request <- GET(url = site_meta_url)
  total_list <-content(request) 
  
 sensor_list <- total_list[["stationSummaries"]][[1]][["dataTypes"]]

   
  station_meta <- as.data.frame(do.call(rbind, sensor_list)) %>%
    mutate(name = as.character(name))%>%
    distinct(name)%>%
    mutate(sensor_list_num = row_number())%>%
    pivot_wider( names_from = "name", values_from = "sensor_list_num")%>%
    mutate(id = total_list[["stationSummaries"]][[1]][["id"]], 
           numid = total_list[["stationSummaries"]][[1]][["numId"]], 
           name = total_list[["stationSummaries"]][[1]][["name"]],
           elevation = total_list[["stationSummaries"]][[1]][["elevation"]],
           lat = total_list[["stationSummaries"]][[1]][["latitude"]],
           long = total_list[["stationSummaries"]][[1]][["longitude"]], 
           site_num = site_number)

  Sys.sleep(1)  

  return(station_meta)
}


```


## Getting meta

```{r meta grab}

#maps to get all metadata/ location of all sensors within JSON
clp_station_meta <- map2_dfr(clp_meta_url$site_url, clp_meta_url$site_number, get_station_meta)


#create a total meta_df that can be referenced in downloading functions later on
final_meta <- clp_station_meta
```

# Q pull

This section will focus on downloading all the Q data available in the CLP and BIGT watershed available on the NovaStar site
## Functions

```{r Q grab function}

#This function actually breaks down the list for a given site into the datetime and value components
unlist_q_data <- function(i){
 unlist(discharge_data[[i]])
}

request <- NA
 

download_q <- function(site_url, site_number) {
  
  #create request to novastar website using url created 
  request <- GET(url = site_url)
  
  #gives content of httr pull
  total_list <- content(request)
  
  #find list number where q is located
  site_meta <- filter(final_meta, numid == site_number)
  
  Q_sensor_num <-  as.numeric(site_meta$DischargeRiver[1]) 
  
    # find list where discharge data is stored
    
  discharge_data <- total_list[["stationSummaries"]][[1]][["ts"]][[Q_sensor_num]][["data"]]
  
  
  q_df <- map_dfr(seq(1, length(discharge_data), 1), unlist_q_data)%>%
    mutate(numid = site_number)
  
  
  return(q_df)
  
   #Sys.sleep(2)
   
  
}

test_site_url <- "https://larimerco-ns5.trilynx-novastar.systems/novastar/data/api/v1/stationSummaries?forOperatorStationDashboard=true&stationNumId=11531&periodStart=2022-01-25T13:59:00-07:00&periodEnd=2023-12-26T13:59:00-07:00"
test_site_number <- "11531"
#
 
 test_q_df <- download_q(site_url = test_site_url,  site_number = test_site_number)
 
# df_11531 <- download_q(site_url = clp_data_url_test$site_url[1],site_number = clp_data_url_test$site_number[1])
# df_11530 <- download_q(site_url = clp_data_url_test$site_url[2],site_number = clp_data_url_test$site_number[2])

```

## Pulling the Q

```{r}

#maps to get all metadata/ location of all sensors within JSON
clp_data_url_test <- head(clp_data_url, 2)

clp_q_station_data <- map2(clp_data_url$site_url, clp_data_url$site_number, download_q)%>%
  list_rbind()

?map2_dfr()

```


## Check the Q
 I'd recommend going to https://larimerco-ns5.trilynx-novastar.systems/novastar/operator/#/stationDashboard/100
 to double check and make sure the data looks similar to the sites you pulled
 
```{r}

test_df_q<- test_q_df%>%
  mutate(nice_dt = substr(dt, 1, nchar(dt)-9),
    datetime = as.POSIXct(dt, format = "%Y-%m-%dT%H:%M"), 
         q_cfs = as.double(v) )

plot_test_Q <- test_df_q%>%
  ggplot(aes( x= datetime, y = q_cfs))+
  geom_line()+
  theme_bw()+
  facet_wrap(~numid)
plot(plot_test_Q)



final_df_q<- clp_q_station_data%>%
  mutate(nice_dt = substr(dt, 1, nchar(dt)-9),
    datetime = as.POSIXct(dt, format = "%Y-%m-%dT%H:%M"), 
         q_cfs = as.double(v) )

plot_test_Q <- final_df_q%>%
  ggplot(aes( x= datetime, y = q_cfs))+
  geom_line()+
  theme_bw()+
  facet_wrap(~numid)
plot(plot_test_Q)


```
